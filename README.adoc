[[Introdução]]
= Introdução
:imagesdir: imgs
:toc:
:toc-title: Conteúdo

== O que é isso?

Esse material é usado para capacitação e transferência de conhecimento de clientes e parceiros da Red Hat Brasil em **OpenShift**, aplicável tanto ao [**Red Hat OpenShift Container Platform**](https://www.openshift.com/container-platform/index.html) (enterprise) quanto ao [**OpenShift OKD**](https://www.okd.io/) (community).

== Por que dessa forma?

Inspirados na cultura open-source, acreditamos que, ao disponibilizar o material de forma aberta, podemos **evoluir o workshop de forma colaborativa e alinhado com as necessidades dos nossos clientes, parceiros e a comunidade**.

Este trabalho está licenciado sob a [**Licença Atribuição-NãoComercial-CompartilhaIgual 4.0 Internacional Creative Commons (CC BY-NC-SA 4.0)**](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.pt_BR).

== Como usar?

**Não existe uma maneira certa ou errada de usar o conteúdo deste material.** Você poderia seguir como um roteiro independente, usando a sua máquina particular como ambiente de experimentações, ou você pode se reunir com colegas e compartilhar a experiência.

**Se você tiver interesse de participar de um workshop com o time Red Hat Brasil, entre em contato com o seu time de contas/parceiro!**

== Para o Instrutor do Test Drive

=== Etherpad

To install etherpad on OpenShift go to https://github.com/luszczynski/openshift-etherpad for instructions.

=== Terminal

If you created your OpenShift environment using RHPDS, you problably have a project called `terminal`. Use it.

Or you can also create a terminal inside OpenShift by running:

[source,bash]
----
# You must change this var according your environment
SUBDOMAIN=apps.cluster-dd3e.dd3e.example.opentlc.com

# Create a new project
oc new-project terminal-workshop

# Create terminal
oc process -f https://raw.githubusercontent.com/openshift-homeroom/workshop-spawner/develop/templates/terminal-server-production.json \
  --param SPAWNER_NAMESPACE=`oc project --short` \
  --param CLUSTER_SUBDOMAIN=$SUBDOMAIN | oc apply -f - -n terminal-workshop
----

=== Serverless

Create a namespace `knative-serving`

[source,bash]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: knative-serving
EOF
----

Create Subscription

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: "serverless-operator"
  namespace: "openshift-operators"
spec:
  channel: "4.5"
  installPlanApproval: Automatic
  name: serverless-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
----

Wait until operator installation is succeeded. You can check that by running:

[source,bash]
----
oc get csv -n knative-serving

NAME                         DISPLAY                         VERSION   REPLACES   PHASE
serverless-operator.v1.7.1   OpenShift Serverless Operator   1.7.1                Succeeded
----

Create KnativeServing

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operator.knative.dev/v1alpha1
kind: KnativeServing
metadata:
  name: knative-serving
  namespace: knative-serving
EOF
----

Create KnativeEventing project

[source,bash]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: knative-eventing
EOF
----

Create KnativeEventing CR

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operator.knative.dev/v1alpha1
kind: KnativeEventing
metadata:
  name: knative-eventing
  labels: {}
  namespace: knative-eventing
spec: {}
EOF
----

=== Pipeline

To install the pipeline operator, run:

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: openshift-pipelines-operator
  namespace: openshift-operators
spec:
  channel: ocp-4.5
  installPlanApproval: Automatic
  name: openshift-pipelines-operator-rh
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
----

=== Logging

==== Install ElasticSearch Operator

Create namespace `openshift-operators-redhat`

[source,bash]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-operators-redhat
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-monitoring: "true"
EOF
----

Create a namespace `openshift-logging`

[source,bash]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-logging
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-monitoring: "true"
EOF
----

Create Operator Group

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-operators-redhat
  namespace: openshift-operators-redhat
spec: {}
EOF
----

Create Subscription

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: "elasticsearch-operator"
  namespace: "openshift-operators-redhat" 
spec:
  channel: "4.5" 
  installPlanApproval: "Automatic"
  source: "redhat-operators" 
  sourceNamespace: "openshift-marketplace"
  name: "elasticsearch-operator"
EOF
----

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: cluster-logging
  namespace: openshift-logging 
spec:
  targetNamespaces:
  - openshift-logging
EOF
----

[source,bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: cluster-logging
  namespace: openshift-logging 
spec:
  channel: "4.5" 
  name: cluster-logging
  source: redhat-operators 
  sourceNamespace: openshift-marketplace
EOF
----

Create instance of Cluster Logging.

For HA, use:

[source,bash]
----
oc apply -f - <<EOF
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance" 
  namespace: "openshift-logging"
spec:
  managementState: "Managed"  
  logStore:
    type: "elasticsearch"  
    retentionPolicy: 
      application:
        maxAge: 1d
      infra:
        maxAge: 1d
      audit:
        maxAge: 1d
    elasticsearch:
      nodeCount: 3
      storage: {}
      redundancyPolicy: "SingleRedundancy"
  visualization:
    type: "kibana"  
    kibana:
      replicas: 1
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *" 
  collection:
    logs:
      type: "fluentd"  
      fluentd: {}
EOF
----

For non-HA environment, use:

[source,bash]
----
oc apply -f - <<EOF
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    retentionPolicy:
      application:
        maxAge: 1d
      infra:
        maxAge: 1d
      audit:
        maxAge: 1d
    elasticsearch:
      nodeCount: 1
      storage: {}
      redundancyPolicy: "ZeroRedundancy"
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
EOF
----

=== Workshopper

This is the documentation every customer/student will see during the labs. It must be deployed as a container inside OpenShift.

==== Local

If you want to develop and improve the docs, you can run it locally using one of the two methods below:

===== Using podman

If you want to check the documentation locally, run:

```bash
# Clone this project
git clone https://github.com/luszczynski/test-drive-openshift.git && cd test-drive-openshift.git

# Run the workshopper container
podman run -it --rm -p 8080:8080 -v $(pwd)/parte-2-openshift-4x:/app-data \
              -e CONTENT_URL_PREFIX="file:///app-data" \
              -e LOG_TO_STDOUT=true \
              -e WORKSHOPS_URLS="file:///app-data/_workshop1.yml" \
              quay.io/jamesfalkner/workshopper        
```

If you have any problem regarding permission when using podman, try disabling the selinux running

```bash
setenforce 0
```

===== Using docker

```bash
# Clone this project
git clone https://github.com/luszczynski/test-drive-openshift.git && cd test-drive-openshift.git

# Run the workshopper container
docker run -it --rm -p 8080:8080 -v $(pwd)/parte-2-openshift-4x:/app-data \
              -e CONTENT_URL_PREFIX="file:///app-data" \
              -e LOG_TO_STDOUT=true \
              -e WORKSHOPS_URLS="file:///app-data/_workshop1.yml" \
              quay.io/jamesfalkner/workshopper
```

==== Install doc on OpenShift

Before beginning your workshop, install the documentation in your OpenShift environment by running the following commands:

NOTE: Remember to change the URLs below according to your environment.

```bash
# Usually you do not need to change this URLs
WORKSHOP_URLS="https://raw.githubusercontent.com/luszczynski/test-drive-openshift/v4.5/parte-2-openshift-4x/_workshop1.yml"
ISSUES_URL="https://github.com/luszczynski/test-drive-openshift/issues"

# Change these vars according to your environment
OPENSHIFT_MASTER_URL="https://console-openshift-console.apps.cluster-brasilia-d6ec.brasilia-d6ec.example.opentlc.com/"
ETHERPAD_URL="http://etherpad-etherpad.apps.cluster-brasilia-d6ec.brasilia-d6ec.example.opentlc.com/p/workshop"
TERMINAL_URL="https://terminal-terminal.apps.cluster-brasilia-d6ec.brasilia-d6ec.example.opentlc.com/"
OPENSHIFT_API_URL="https://api.cluster-brasilia-da5c.brasilia-da5c.example.opentlc.com:6443"
LOGGING_URL="https://kibana-openshift-logging.apps.cluster-brasilia-325f.brasilia-325f.example.opentlc.com/"

oc new-project workshopper --display-name="Workshopper"

oc new-app quay.io/osevg/workshopper --name=workshopper \
      -e WORKSHOPS_URLS=$WORKSHOP_URLS \
      -e ISSUES_URL=$ISSUES_URL \
      -e OPENSHIFT_MASTER_URL=$OPENSHIFT_MASTER_URL \
      -e ETHERPAD_URL=$ETHERPAD_URL \
      -e TERMINAL_URL=$TERMINAL_URL \
      -e OPENSHIFT_API_URL=$OPENSHIFT_API_URL \
      -e LOGGING_URL=$LOGGING_URL \
      -e LOG_TO_STDOUT=true -n workshopper

oc expose svc/workshopper -n workshopper
```

=== Observação

**Para o S2I com o Quarkus** funcionar importar o template template-openjdk11-rhel8-s2i.yaml para o namespace **openshift**. Após isso importar também a secret para a service account default em cada projeto para fazer pulling da imagem do **registry.redhat.io**.